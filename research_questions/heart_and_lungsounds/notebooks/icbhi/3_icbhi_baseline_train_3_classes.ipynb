{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "710c38a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f73e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CSV_PATH = Path(\"../../data/processed/icbhi/icbhi_segments.csv\")\n",
    "WAV_DIR  = Path(\"../../data/processed/icbhi/audio_4000hz_bp_segments\")\n",
    "\n",
    "OUT_DIR = Path(\"../../data/processed/icbhi/baseline_runs_all_labels\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8656152",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "LABEL_COL   = \"acoustic_label\"\n",
    "PATIENT_COL = \"patient_id\"\n",
    "\n",
    "df[LABEL_COL] = df[LABEL_COL].astype(str).str.strip().str.lower()\n",
    "\n",
    "EXPECTED = {\"normal\", \"crackle\", \"wheeze\", \"mixed\", \"reject\"}\n",
    "bad_labels = set(df[LABEL_COL].unique()) - EXPECTED\n",
    "if bad_labels:\n",
    "    raise ValueError(f\"Unexpected labels: {sorted(bad_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d756154d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>record_id</th>\n",
       "      <th>file_name</th>\n",
       "      <th>segment_index</th>\n",
       "      <th>seg_start_sec</th>\n",
       "      <th>seg_end_sec</th>\n",
       "      <th>seg_duration_sec</th>\n",
       "      <th>acoustic_label</th>\n",
       "      <th>frac_normal</th>\n",
       "      <th>frac_wheeze</th>\n",
       "      <th>frac_crackle</th>\n",
       "      <th>frac_crackle_wheeze</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>chest_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>101_1b1_Al_sc_Meditron.wav</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>101_1b1_Al_sc_Meditron.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>101_1b1_Al_sc_Meditron.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>101_1b1_Al_sc_Meditron.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101_1b1_Al_sc_Meditron</td>\n",
       "      <td>101_1b1_Al_sc_Meditron.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>URTI</td>\n",
       "      <td>Al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17929</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE.wav</td>\n",
       "      <td>13</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>reject</td>\n",
       "      <td>0.723</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17930</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE.wav</td>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17931</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE.wav</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17932</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE.wav</td>\n",
       "      <td>16</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>reject</td>\n",
       "      <td>0.597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Pl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17933</th>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE</td>\n",
       "      <td>226_1b1_Pl_sc_LittC2SE.wav</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>reject</td>\n",
       "      <td>0.223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>226</td>\n",
       "      <td>Pneumonia</td>\n",
       "      <td>Pl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17934 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    record_id                   file_name  segment_index  \\\n",
       "0      101_1b1_Al_sc_Meditron  101_1b1_Al_sc_Meditron.wav              0   \n",
       "1      101_1b1_Al_sc_Meditron  101_1b1_Al_sc_Meditron.wav              1   \n",
       "2      101_1b1_Al_sc_Meditron  101_1b1_Al_sc_Meditron.wav              2   \n",
       "3      101_1b1_Al_sc_Meditron  101_1b1_Al_sc_Meditron.wav              3   \n",
       "4      101_1b1_Al_sc_Meditron  101_1b1_Al_sc_Meditron.wav              4   \n",
       "...                       ...                         ...            ...   \n",
       "17929  226_1b1_Pl_sc_LittC2SE  226_1b1_Pl_sc_LittC2SE.wav             13   \n",
       "17930  226_1b1_Pl_sc_LittC2SE  226_1b1_Pl_sc_LittC2SE.wav             14   \n",
       "17931  226_1b1_Pl_sc_LittC2SE  226_1b1_Pl_sc_LittC2SE.wav             15   \n",
       "17932  226_1b1_Pl_sc_LittC2SE  226_1b1_Pl_sc_LittC2SE.wav             16   \n",
       "17933  226_1b1_Pl_sc_LittC2SE  226_1b1_Pl_sc_LittC2SE.wav             17   \n",
       "\n",
       "       seg_start_sec  seg_end_sec  seg_duration_sec acoustic_label  \\\n",
       "0                0.0          2.5               2.5         normal   \n",
       "1                1.0          3.5               2.5         normal   \n",
       "2                2.0          4.5               2.5         normal   \n",
       "3                3.0          5.5               2.5         normal   \n",
       "4                4.0          6.5               2.5         normal   \n",
       "...              ...          ...               ...            ...   \n",
       "17929           13.0         15.5               2.5         reject   \n",
       "17930           14.0         16.5               2.5         normal   \n",
       "17931           15.0         17.5               2.5         normal   \n",
       "17932           16.0         18.5               2.5         reject   \n",
       "17933           17.0         19.5               2.5         reject   \n",
       "\n",
       "       frac_normal  frac_wheeze  frac_crackle  frac_crackle_wheeze  \\\n",
       "0            0.986          0.0         0.000                  0.0   \n",
       "1            1.000          0.0         0.000                  0.0   \n",
       "2            1.000          0.0         0.000                  0.0   \n",
       "3            1.000          0.0         0.000                  0.0   \n",
       "4            1.000          0.0         0.000                  0.0   \n",
       "...            ...          ...           ...                  ...   \n",
       "17929        0.723          0.0         0.277                  0.0   \n",
       "17930        1.000          0.0         0.000                  0.0   \n",
       "17931        0.997          0.0         0.003                  0.0   \n",
       "17932        0.597          0.0         0.403                  0.0   \n",
       "17933        0.223          0.0         0.777                  0.0   \n",
       "\n",
       "       patient_id  diagnosis chest_location  \n",
       "0             101       URTI             Al  \n",
       "1             101       URTI             Al  \n",
       "2             101       URTI             Al  \n",
       "3             101       URTI             Al  \n",
       "4             101       URTI             Al  \n",
       "...           ...        ...            ...  \n",
       "17929         226  Pneumonia             Pl  \n",
       "17930         226  Pneumonia             Pl  \n",
       "17931         226  Pneumonia             Pl  \n",
       "17932         226  Pneumonia             Pl  \n",
       "17933         226  Pneumonia             Pl  \n",
       "\n",
       "[17934 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58d442bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acoustic_label\n",
       "normal     7727\n",
       "crackle    4090\n",
       "reject     2469\n",
       "mixed      1903\n",
       "wheeze     1745\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['acoustic_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67ff1eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop reject labels\n",
    "df = df[df[LABEL_COL] != \"reject\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7f728e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop mixed labels\n",
    "df = df[df[LABEL_COL] != \"mixed\"].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72e65bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEGMENT_NAME_PATTERN = \"{stem}_seg{seg:03d}.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3d7c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_segment_path(file_name: str, segment_index: int) -> Path:\n",
    "    stem = str(file_name).strip()\n",
    "    if stem.lower().endswith(\".wav\"):\n",
    "        stem = stem[:-4]\n",
    "    fn = SEGMENT_NAME_PATTERN.format(stem=stem, seg=int(segment_index))\n",
    "    return (WAV_DIR / fn).resolve()\n",
    "\n",
    "df[\"audio_path\"] = df.apply(lambda r: build_segment_path(r[\"file_name\"], r[\"segment_index\"]), axis=1)\n",
    "df = df[df[\"audio_path\"].apply(lambda p: p.exists())].reset_index(drop=True)\n",
    "\n",
    "p0 = df.loc[0, \"audio_path\"]\n",
    "info = sf.info(str(p0))\n",
    "if info.samplerate != 4000:\n",
    "    raise ValueError(f\"Unexpected samplerate {info.samplerate} in {p0}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83f479d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df[PATIENT_COL].astype(str)\n",
    "\n",
    "gss1 = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)\n",
    "train_idx, test_idx = next(gss1.split(df, groups=groups))\n",
    "df_trainval = df.iloc[train_idx].reset_index(drop=True)\n",
    "df_test = df.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "groups_tv = df_trainval[PATIENT_COL].astype(str)\n",
    "gss2 = GroupShuffleSplit(n_splits=1, test_size=0.20, random_state=SEED)\n",
    "train_idx2, val_idx2 = next(gss2.split(df_trainval, groups=groups_tv))\n",
    "df_train = df_trainval.iloc[train_idx2].reset_index(drop=True)\n",
    "df_val = df_trainval.iloc[val_idx2].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "676d00c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acoustic_label\n",
       "normal     7727\n",
       "crackle    4090\n",
       "wheeze     1745\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[LABEL_COL].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f21e9127",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"normal\", \"crackle\", \"wheeze\"]\n",
    "label2id = {l: i for i, l in enumerate(LABELS)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca6fcf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_weights(df_train: pd.DataFrame) -> torch.Tensor:\n",
    "    counts = df_train[LABEL_COL].value_counts().reindex(LABELS, fill_value=0).values.astype(np.float32)\n",
    "    weights = counts.sum() / (len(LABELS) * np.maximum(counts, 1.0))\n",
    "    return torch.tensor(weights, dtype=torch.float32)\n",
    "\n",
    "def make_balanced_subset(df_train: pd.DataFrame, normal_name=\"normal\") -> pd.DataFrame:\n",
    "    vc = df_train[LABEL_COL].value_counts()\n",
    "    if normal_name not in vc.index:\n",
    "        return df_train\n",
    "    non_normal = vc.drop(index=[normal_name])\n",
    "    if len(non_normal) == 0:\n",
    "        return df_train\n",
    "    target = int(non_normal.min())\n",
    "    df_normal = df_train[df_train[LABEL_COL] == normal_name].sample(\n",
    "        n=min(target, int(vc[normal_name])),\n",
    "        random_state=SEED\n",
    "    )\n",
    "    df_rest = df_train[df_train[LABEL_COL] != normal_name]\n",
    "    return pd.concat([df_rest, df_normal], ignore_index=True).sample(frac=1, random_state=SEED).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30bdea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS_TARGET = 4000\n",
    "N_FFT = 256\n",
    "HOP_LENGTH = 64\n",
    "N_MELS = 64\n",
    "FMIN = 20\n",
    "FMAX = FS_TARGET // 2\n",
    "\n",
    "CACHE_DIR = OUT_DIR / \"features_cache\"\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7aade09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax01(x: np.ndarray) -> np.ndarray:\n",
    "    x_min = float(np.min(x))\n",
    "    x_max = float(np.max(x))\n",
    "    if (x_max - x_min) < 1e-12:\n",
    "        return np.zeros_like(x, dtype=np.float32)\n",
    "    return ((x - x_min) / (x_max - x_min)).astype(np.float32)\n",
    "\n",
    "def feat_logmel(y: np.ndarray, sr: int) -> np.ndarray:\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_fft=N_FFT, hop_length=HOP_LENGTH,\n",
    "        n_mels=N_MELS, fmin=FMIN, fmax=FMAX, power=2.0\n",
    "    )\n",
    "    S_db = librosa.power_to_db(S, ref=np.max)\n",
    "    return minmax01(S_db)\n",
    "\n",
    "def feat_stft(y: np.ndarray, sr: int) -> np.ndarray:\n",
    "    D = librosa.stft(y=y, n_fft=N_FFT, hop_length=HOP_LENGTH, center=True)\n",
    "    P = (np.abs(D) ** 2).astype(np.float32)\n",
    "    P_db = librosa.power_to_db(P, ref=np.max)\n",
    "    return minmax01(P_db)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55bed1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_key(row) -> str:\n",
    "    stem = str(row[\"file_name\"]).replace(\".wav\", \"\")\n",
    "    seg = int(row[\"segment_index\"])\n",
    "    return f\"{stem}__seg_{seg:03d}\"\n",
    "\n",
    "def cache_path(feature_type: str, key: str) -> Path:\n",
    "    d = CACHE_DIR / feature_type\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "    return d / f\"{key}.npz\"\n",
    "\n",
    "def extract_and_cache(row, feature_type: str) -> Path:\n",
    "    key = segment_key(row)\n",
    "    cp = cache_path(feature_type, key)\n",
    "    if cp.exists():\n",
    "        return cp\n",
    "\n",
    "    audio_path = Path(row[\"audio_path\"])\n",
    "    if not audio_path.exists():\n",
    "        raise FileNotFoundError(str(audio_path))\n",
    "\n",
    "    y, sr = sf.read(str(audio_path), dtype=\"float32\")\n",
    "    if y.ndim > 1:\n",
    "        y = np.mean(y, axis=1)\n",
    "\n",
    "    if sr != FS_TARGET:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=FS_TARGET)\n",
    "        sr = FS_TARGET\n",
    "\n",
    "    if feature_type == \"logmel\":\n",
    "        X = feat_logmel(y, sr)\n",
    "    elif feature_type == \"stft\":\n",
    "        X = feat_stft(y, sr)\n",
    "    else:\n",
    "        raise ValueError(feature_type)\n",
    "\n",
    "    X = X[..., None].astype(np.float32)\n",
    "    y_id = label2id[str(row[LABEL_COL]).strip().lower()]\n",
    "\n",
    "    np.savez_compressed(cp, X=X, y=y_id)\n",
    "    return cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ebff77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CachedFeatureDataset(Dataset):\n",
    "    def __init__(self, df_split: pd.DataFrame, feature_type: str):\n",
    "        self.df = df_split.reset_index(drop=True).copy()\n",
    "        self.feature_type = feature_type\n",
    "        self.cache_files = []\n",
    "        for i in range(len(self.df)):\n",
    "            row = self.df.iloc[i]\n",
    "            cp = extract_and_cache(row, feature_type)\n",
    "            self.cache_files.append(str(cp))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.cache_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        z = np.load(self.cache_files[idx])\n",
    "        X = z[\"X\"]\n",
    "        y = int(z[\"y\"])\n",
    "        X = torch.from_numpy(X).permute(2, 0, 1).contiguous()\n",
    "        return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90a18caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, n_classes: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 8, kernel_size=(4, 2), padding=(1, 0)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "\n",
    "            nn.Conv2d(8, 32, kernel_size=(4, 2), padding=(1, 0)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=(4, 2), padding=(1, 0)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
    "\n",
    "            nn.Conv2d(32, 32, kernel_size=(4, 2), padding=(1, 0)),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 2)),  # reduced stride in height dim\n",
    "        )\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.25)\n",
    "        self.fc1 = nn.Linear(1, 2000)  # placeholder; we set in forward after we know flatten dim\n",
    "        self.dropout2 = nn.Dropout(p=0.50)\n",
    "        self.out = nn.Linear(2000, n_classes)\n",
    "\n",
    "        self._fc_initialized = False\n",
    "\n",
    "    def _init_fc(self, x):\n",
    "        flat_dim = x.shape[1]\n",
    "        self.fc1 = nn.Linear(flat_dim, 2000).to(x.device)\n",
    "        self._fc_initialized = True\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        if not self._fc_initialized:\n",
    "            self._init_fc(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f2b1b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(model, loader, optimizer, criterion, train=True):\n",
    "    model.train(train)\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for X, y in loader:\n",
    "        X = X.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        total_loss += float(loss.item()) * X.size(0)\n",
    "        pred = logits.argmax(dim=1)\n",
    "        correct += int((pred == y).sum().item())\n",
    "        total += int(X.size(0))\n",
    "    return total_loss / max(total, 1), correct / max(total, 1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, loader):\n",
    "    model.eval()\n",
    "    ys, ps = [], []\n",
    "    for X, y in loader:\n",
    "        X = X.to(DEVICE)\n",
    "        logits = model(X)\n",
    "        pred = logits.argmax(dim=1).cpu().numpy()\n",
    "        ys.extend(y.numpy().tolist())\n",
    "        ps.extend(pred.tolist())\n",
    "    return np.array(ys), np.array(ps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70bd83c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(feature_type=\"logmel\", use_weights=False, use_balanced=False,\n",
    "                   epochs=50, batch_size=8, lr=1e-3):\n",
    "    exp_name = f\"{feature_type}__weights_{int(use_weights)}__balanced_{int(use_balanced)}\"\n",
    "    exp_dir = OUT_DIR / exp_name\n",
    "    exp_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_df = make_balanced_subset(df_train) if use_balanced else df_train\n",
    "\n",
    "    ds_train = CachedFeatureDataset(train_df, feature_type)\n",
    "    ds_val   = CachedFeatureDataset(df_val, feature_type)\n",
    "    ds_test  = CachedFeatureDataset(df_test, feature_type)\n",
    "\n",
    "    dl_train = DataLoader(ds_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    dl_val   = DataLoader(ds_val, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    dl_test  = DataLoader(ds_test, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "    model = SmallCNN(n_classes=len(LABELS)).to(DEVICE)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    if use_weights:\n",
    "        w = compute_class_weights(train_df).to(DEVICE)\n",
    "        criterion = nn.CrossEntropyLoss(weight=w)\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    cfg = {\n",
    "        \"feature_type\": feature_type,\n",
    "        \"use_weights\": use_weights,\n",
    "        \"use_balanced\": use_balanced,\n",
    "        \"epochs\": epochs,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"lr\": lr,\n",
    "        \"seed\": SEED,\n",
    "        \"labels\": LABELS,\n",
    "        \"csv_path\": str(CSV_PATH),\n",
    "        \"wav_dir\": str(WAV_DIR),\n",
    "        \"segment_name_pattern\": SEGMENT_NAME_PATTERN,\n",
    "    }\n",
    "    (exp_dir / \"config.json\").write_text(json.dumps(cfg, indent=2))\n",
    "\n",
    "    best_val = float(\"inf\")\n",
    "    best_path = exp_dir / \"best.pt\"\n",
    "\n",
    "    history = []\n",
    "    for ep in range(1, epochs + 1):\n",
    "        tr_loss, tr_acc = run_epoch(model, dl_train, optimizer, criterion, train=True)\n",
    "        va_loss, va_acc = run_epoch(model, dl_val, optimizer, criterion, train=False)\n",
    "        history.append({\n",
    "            \"epoch\": ep,\n",
    "            \"train_loss\": tr_loss, \"train_acc\": tr_acc,\n",
    "            \"val_loss\": va_loss, \"val_acc\": va_acc\n",
    "        })\n",
    "        if va_loss < best_val:\n",
    "            best_val = va_loss\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "\n",
    "    pd.DataFrame(history).to_csv(exp_dir / \"history.csv\", index=False)\n",
    "\n",
    "    model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
    "    y_true, y_pred = predict(model, dl_test)\n",
    "\n",
    "    report = classification_report(y_true, y_pred, target_names=LABELS, digits=4, output_dict=True)\n",
    "    pd.DataFrame(report).to_csv(exp_dir / \"test_classification_report.csv\")\n",
    "\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    np.save(exp_dir / \"confusion_matrix.npy\", cm)\n",
    "\n",
    "    return exp_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d33c731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_210764\\694616471.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
      "c:\\Users\\MSI\\Documents\\Persoonlijke Projecten\\AI-Onderzoeksvragen\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\MSI\\Documents\\Persoonlijke Projecten\\AI-Onderzoeksvragen\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\MSI\\Documents\\Persoonlijke Projecten\\AI-Onderzoeksvragen\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_210764\\694616471.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_210764\\694616471.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
      "C:\\Users\\MSI\\AppData\\Local\\Temp\\ipykernel_210764\\694616471.py:59: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n"
     ]
    }
   ],
   "source": [
    "runs = []\n",
    "for feat in [\"logmel\", \"stft\"]:\n",
    "    for w in [False, True]:\n",
    "        for b in [False, True]:\n",
    "            runs.append(run_experiment(feature_type=feat, use_weights=w, use_balanced=b, epochs=50))\n",
    "runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ce8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = []\n",
    "\n",
    "for d in runs:\n",
    "    rep_path = Path(d) / \"test_classification_report.csv\"\n",
    "    rep = pd.read_csv(rep_path, index_col=0)\n",
    "\n",
    "    if \"f1-score\" in rep.columns:\n",
    "        macro_f1 = float(rep.loc[\"macro avg\", \"f1-score\"])\n",
    "    elif \"f1-score\" in rep.index:\n",
    "        macro_f1 = float(rep.loc[\"f1-score\", \"macro avg\"])\n",
    "    else:\n",
    "        # last resort: try transpose\n",
    "        rep_t = rep.T\n",
    "        if \"f1-score\" in rep_t.columns:\n",
    "            macro_f1 = float(rep_t.loc[\"macro avg\", \"f1-score\"])\n",
    "        else:\n",
    "            raise KeyError(f\"Could not find macro F1 in {rep_path}\")\n",
    "\n",
    "    summary.append({\"run\": Path(d).name, \"macro_f1\": macro_f1})\n",
    "\n",
    "summary_df = (\n",
    "    pd.DataFrame(summary)\n",
    "      .sort_values(\"macro_f1\", ascending=False)\n",
    "      .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ec48f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def parse_exp_name(exp_dir: Path) -> str:\n",
    "    name = Path(exp_dir).name\n",
    "    parts = name.split(\"__\")\n",
    "    kv = {}\n",
    "    for p in parts:\n",
    "        if \"_weights_\" in p:\n",
    "            # e.g. logmel__weights_1__balanced_0 (but your pattern is feature__weights_x__balanced_y)\n",
    "            pass\n",
    "    # robust parse: feature_type is first token, then weights_x, balanced_y\n",
    "    feature_type = parts[0] if len(parts) > 0 else name\n",
    "    weights = None\n",
    "    balanced = None\n",
    "    for p in parts[1:]:\n",
    "        if p.startswith(\"weights_\"):\n",
    "            weights = p.split(\"weights_\")[-1]\n",
    "        if p.startswith(\"balanced_\"):\n",
    "            balanced = p.split(\"balanced_\")[-1]\n",
    "\n",
    "    def yn(v):\n",
    "        if v is None:\n",
    "            return \"Unknown\"\n",
    "        return \"Yes\" if str(v) in {\"1\", \"true\", \"True\", \"yes\", \"Yes\"} else \"No\"\n",
    "\n",
    "    title = f\"ICBHI Baseline | Features: {feature_type.upper()} | Class Weights: {yn(weights)} | Balanced Subset: {yn(balanced)}\"\n",
    "    return title\n",
    "\n",
    "def load_report_csv(report_path: Path) -> pd.DataFrame:\n",
    "    rep = pd.read_csv(report_path, index_col=0)\n",
    "    # Ensure rows are classes/avg and columns are metrics\n",
    "    # If currently metrics are rows and classes are columns -> transpose\n",
    "    if \"f1-score\" not in rep.columns and \"f1-score\" in rep.index:\n",
    "        rep = rep.T\n",
    "    return rep\n",
    "\n",
    "def plot_train_curves(exp_dir, save=True, dpi=300):\n",
    "    exp_dir = Path(exp_dir)\n",
    "    title = parse_exp_name(exp_dir)\n",
    "\n",
    "    hist_path = exp_dir / \"history.csv\"\n",
    "    if not hist_path.exists():\n",
    "        raise FileNotFoundError(hist_path)\n",
    "\n",
    "    hist = pd.read_csv(hist_path)\n",
    "\n",
    "    fig = plt.figure(figsize=(11, 4.5), dpi=dpi)\n",
    "    fig.suptitle(title, fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.plot(hist[\"epoch\"], hist[\"train_acc\"], label=\"Train Acc\", linewidth=2)\n",
    "    ax1.plot(hist[\"epoch\"], hist[\"val_acc\"], label=\"Val Acc\", linewidth=2)\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_ylim(0, 1.0)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend(frameon=False)\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.plot(hist[\"epoch\"], hist[\"train_loss\"], label=\"Train Loss\", linewidth=2)\n",
    "    ax2.plot(hist[\"epoch\"], hist[\"val_loss\"], label=\"Val Loss\", linewidth=2)\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.legend(frameon=False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        out = exp_dir / \"plot_curves_acc_loss.png\"\n",
    "        fig.savefig(out, bbox_inches=\"tight\")\n",
    "    return fig\n",
    "\n",
    "def plot_confusion_matrix(exp_dir, labels, normalize=None, save=True, dpi=300):\n",
    "    \"\"\"\n",
    "    normalize:\n",
    "      None -> raw counts\n",
    "      \"true\" -> rows sum to 1 (recall-normalized)\n",
    "      \"pred\" -> cols sum to 1 (precision-normalized)\n",
    "    \"\"\"\n",
    "    exp_dir = Path(exp_dir)\n",
    "    title = parse_exp_name(exp_dir)\n",
    "\n",
    "    cm_path = exp_dir / \"confusion_matrix.npy\"\n",
    "    if not cm_path.exists():\n",
    "        raise FileNotFoundError(cm_path)\n",
    "\n",
    "    cm = np.load(cm_path).astype(float)\n",
    "\n",
    "    if normalize == \"true\":\n",
    "        row_sums = cm.sum(axis=1, keepdims=True)\n",
    "        cm_disp = np.divide(cm, row_sums, out=np.zeros_like(cm), where=row_sums != 0)\n",
    "        subtitle = \"Confusion Matrix (Normalized by True Class)\"\n",
    "        fmt = \".2f\"\n",
    "    elif normalize == \"pred\":\n",
    "        col_sums = cm.sum(axis=0, keepdims=True)\n",
    "        cm_disp = np.divide(cm, col_sums, out=np.zeros_like(cm), where=col_sums != 0)\n",
    "        subtitle = \"Confusion Matrix (Normalized by Predicted Class)\"\n",
    "        fmt = \".2f\"\n",
    "    else:\n",
    "        cm_disp = cm\n",
    "        subtitle = \"Confusion Matrix (Counts)\"\n",
    "        fmt = \".0f\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.5, 6), dpi=dpi)\n",
    "    ax.set_title(f\"{title}\\n{subtitle}\", fontsize=13, fontweight=\"bold\", pad=12)\n",
    "\n",
    "    im = ax.imshow(cm_disp, interpolation=\"nearest\")\n",
    "    cbar = fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "    ax.set_xticks(np.arange(len(labels)))\n",
    "    ax.set_yticks(np.arange(len(labels)))\n",
    "    ax.set_xticklabels([l.upper() for l in labels], rotation=30, ha=\"right\")\n",
    "    ax.set_yticklabels([l.upper() for l in labels])\n",
    "\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "\n",
    "    # annotate\n",
    "    thresh = (cm_disp.max() + cm_disp.min()) / 2.0 if cm_disp.size else 0.0\n",
    "    for i in range(cm_disp.shape[0]):\n",
    "        for j in range(cm_disp.shape[1]):\n",
    "            val = cm_disp[i, j]\n",
    "            ax.text(\n",
    "                j, i, format(val, fmt),\n",
    "                ha=\"center\", va=\"center\",\n",
    "                fontsize=10,\n",
    "                color=\"white\" if val > thresh else \"black\"\n",
    "            )\n",
    "\n",
    "    ax.set_xlim(-0.5, len(labels) - 0.5)\n",
    "    ax.set_ylim(len(labels) - 0.5, -0.5)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        out = exp_dir / f\"plot_confusion_matrix_{normalize or 'counts'}.png\"\n",
    "        fig.savefig(out, bbox_inches=\"tight\")\n",
    "    return fig\n",
    "\n",
    "def plot_classification_report(exp_dir, save=True, dpi=300):\n",
    "    exp_dir = Path(exp_dir)\n",
    "    title = parse_exp_name(exp_dir)\n",
    "\n",
    "    rep_path = exp_dir / \"test_classification_report.csv\"\n",
    "    if not rep_path.exists():\n",
    "        raise FileNotFoundError(rep_path)\n",
    "\n",
    "    rep = load_report_csv(rep_path)\n",
    "\n",
    "    # Keep only core metrics; align rows in a nice order if present\n",
    "    cols = [c for c in [\"precision\", \"recall\", \"f1-score\", \"support\"] if c in rep.columns]\n",
    "    rep = rep[cols].copy()\n",
    "\n",
    "    row_order = []\n",
    "    for r in [\"normal\", \"crackle\", \"wheeze\", \"accuracy\", \"macro avg\", \"weighted avg\"]:\n",
    "        if r in rep.index:\n",
    "            row_order.append(r)\n",
    "    # also include any other rows not covered\n",
    "    for r in rep.index:\n",
    "        if r not in row_order:\n",
    "            row_order.append(r)\n",
    "    rep = rep.loc[row_order]\n",
    "\n",
    "    # Make it figure-friendly: round metrics\n",
    "    rep_disp = rep.copy()\n",
    "    for c in rep_disp.columns:\n",
    "        if c == \"support\":\n",
    "            rep_disp[c] = rep_disp[c].astype(float).round(0).astype(int)\n",
    "        elif c == \"accuracy\":\n",
    "            rep_disp[c] = rep_disp[c].astype(float).round(4)\n",
    "        else:\n",
    "            rep_disp[c] = rep_disp[c].astype(float).round(4)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8.5, 3.8), dpi=dpi)\n",
    "    ax.set_title(f\"{title}\\nClassification Report (Test Set)\", fontsize=13, fontweight=\"bold\", pad=12)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    table = ax.table(\n",
    "        cellText=rep_disp.values,\n",
    "        rowLabels=[str(i).upper() for i in rep_disp.index],\n",
    "        colLabels=[c.upper() for c in rep_disp.columns],\n",
    "        cellLoc=\"center\",\n",
    "        rowLoc=\"center\",\n",
    "        loc=\"center\"\n",
    "    )\n",
    "\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 1.4)\n",
    "\n",
    "    # Light emphasis for header row/col\n",
    "    for (row, col), cell in table.get_celld().items():\n",
    "        if row == 0:\n",
    "            cell.set_text_props(fontweight=\"bold\")\n",
    "        if col == -1:\n",
    "            cell.set_text_props(fontweight=\"bold\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        out = exp_dir / \"plot_classification_report.png\"\n",
    "        fig.savefig(out, bbox_inches=\"tight\")\n",
    "    return fig\n",
    "\n",
    "def plot_all_for_experiment(exp_dir, labels=(\"normal\", \"crackle\", \"wheeze\"), dpi=300):\n",
    "    exp_dir = Path(exp_dir)\n",
    "    figs = []\n",
    "    figs.append(plot_train_curves(exp_dir, save=True, dpi=dpi))\n",
    "    figs.append(plot_confusion_matrix(exp_dir, labels=labels, normalize=None, save=True, dpi=dpi))\n",
    "    figs.append(plot_confusion_matrix(exp_dir, labels=labels, normalize=\"true\", save=True, dpi=dpi))\n",
    "    figs.append(plot_classification_report(exp_dir, save=True, dpi=dpi))\n",
    "    return figs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d732d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# of alles in een loop\n",
    "for d in runs:\n",
    "    plot_all_for_experiment(d, labels=[\"normal\", \"crackle\", \"wheeze\"], dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc1b515",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
