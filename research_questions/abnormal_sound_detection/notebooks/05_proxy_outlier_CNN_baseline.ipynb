{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b957d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.1+cu126\n",
      "CUDA available: True\n",
      "Number of CUDA devices: 1\n",
      "Current device: 0\n",
      "Device name: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Path to the dataset (relative to the notebook)\n",
    "DATA_ROOT = Path(\"../data\")\n",
    "MACHINE_TYPES = [\"fan\", \"pump\", \"slider\", \"ToyCar\", \"ToyConveyor\", \"valve\"]\n",
    "\n",
    "# Audio and feature configuration\n",
    "SAMPLE_RATE = 16000\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512\n",
    "N_MELS = 128\n",
    "\n",
    "# (voor proxy-outlier gaan we vaak met volledige spectrogrammen werken, maar\n",
    "# het is prima om deze patch-config ook alvast klaar te hebben voor evt. sliding windows)\n",
    "PATCH_FRAMES = 64\n",
    "PATCH_HOP = 32\n",
    "\n",
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Number of CUDA devices:\", torch.cuda.device_count())\n",
    "    print(\"Current device:\", torch.cuda.current_device())\n",
    "    print(\"Device name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    print(\"CUDA not available, falling back to CPU.\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "570ad8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30987\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'path': WindowsPath('../data/fan/train/normal_id_00_00000000.wav'),\n",
       "  'machine_type': 'fan',\n",
       "  'split': 'train',\n",
       "  'label': 0},\n",
       " {'path': WindowsPath('../data/fan/train/normal_id_00_00000001.wav'),\n",
       "  'machine_type': 'fan',\n",
       "  'split': 'train',\n",
       "  'label': 0},\n",
       " {'path': WindowsPath('../data/fan/train/normal_id_00_00000002.wav'),\n",
       "  'machine_type': 'fan',\n",
       "  'split': 'train',\n",
       "  'label': 0},\n",
       " {'path': WindowsPath('../data/fan/train/normal_id_00_00000003.wav'),\n",
       "  'machine_type': 'fan',\n",
       "  'split': 'train',\n",
       "  'label': 0},\n",
       " {'path': WindowsPath('../data/fan/train/normal_id_00_00000004.wav'),\n",
       "  'machine_type': 'fan',\n",
       "  'split': 'train',\n",
       "  'label': 0}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scan_files(data_root=DATA_ROOT, machine_types=None):\n",
    "    \"\"\"\n",
    "    Scan ../data and return a list of dictionaries:\n",
    "        {\n",
    "            'path': Path,\n",
    "            'machine_type': str,\n",
    "            'split': 'train' or 'test',\n",
    "            'label': 0 (normal) or 1 (anomaly)\n",
    "        }\n",
    "\n",
    "    Deze structuur is hetzelfde als in de IDC-TransAE notebook,\n",
    "    zodat je file_list in beide experimenten uitwisselbaar is.\n",
    "    \"\"\"\n",
    "    if machine_types is None:\n",
    "        machine_types = MACHINE_TYPES\n",
    "\n",
    "    all_files = []\n",
    "\n",
    "    for mtype in machine_types:\n",
    "        for split in [\"train\", \"test\"]:\n",
    "            split_dir = data_root / mtype / split\n",
    "            if not split_dir.exists():\n",
    "                continue\n",
    "\n",
    "            for fname in sorted(split_dir.glob(\"*.wav\")):\n",
    "                name_lower = fname.name.lower()\n",
    "\n",
    "                if \"normal\" in name_lower:\n",
    "                    label = 0\n",
    "                elif \"anomaly\" in name_lower:\n",
    "                    label = 1\n",
    "                else:\n",
    "                    # fallback als de bestandsnaam geen expliciet label bevat\n",
    "                    label = None\n",
    "\n",
    "                all_files.append({\n",
    "                    \"path\": fname,\n",
    "                    \"machine_type\": mtype,\n",
    "                    \"split\": split,\n",
    "                    \"label\": label,\n",
    "                })\n",
    "\n",
    "    return all_files\n",
    "\n",
    "\n",
    "file_list = scan_files()\n",
    "print(len(file_list))\n",
    "file_list[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a6200ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path, sr=SAMPLE_RATE):\n",
    "    \"\"\"\n",
    "    Load audio file as mono at a fixed sample rate.\n",
    "\n",
    "    Returns:\n",
    "        audio: np.ndarray, shape (samples,)\n",
    "        sr   : int, sample rate\n",
    "    \"\"\"\n",
    "    audio, sr = librosa.load(path, sr=sr, mono=True)\n",
    "    return audio, sr\n",
    "\n",
    "\n",
    "def audio_to_logmelspec(\n",
    "    audio,\n",
    "    sr,\n",
    "    n_fft=N_FFT,\n",
    "    hop_length=HOP_LENGTH,\n",
    "    n_mels=N_MELS,\n",
    "):\n",
    "    \"\"\"\n",
    "    Convert a waveform into a log-Mel spectrogram.\n",
    "    audio : 1D numpy array\n",
    "    sr    : sample rate\n",
    "\n",
    "    Returns:\n",
    "        log-Mel spectrogram of shape (n_mels, n_frames)\n",
    "    \"\"\"\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=audio,\n",
    "        sr=sr,\n",
    "        n_fft=n_fft,\n",
    "        hop_length=hop_length,\n",
    "        n_mels=n_mels,\n",
    "        power=2.0,\n",
    "    )\n",
    "\n",
    "    logS = np.log(S + 1e-12)\n",
    "    return logS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c1f5818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_target_vs_po_lists(file_list, target_type):\n",
    "    \"\"\"\n",
    "    Bouw twee lijsten:\n",
    "        target_train : alle NORMAL train samples van target machine\n",
    "        po_train     : alle NORMAL train samples van alle andere machines\n",
    "\n",
    "    Voor evaluatie:\n",
    "        target_test_normal\n",
    "        target_test_anomaly\n",
    "\n",
    "    Returns dictionary met 4 lijsten.\n",
    "    \"\"\"\n",
    "    target_train = []\n",
    "    po_train = []\n",
    "    target_test_normal = []\n",
    "    target_test_anomaly = []\n",
    "\n",
    "    for entry in file_list:\n",
    "        m = entry[\"machine_type\"]\n",
    "        split = entry[\"split\"]\n",
    "        label = entry[\"label\"]\n",
    "\n",
    "        # Train splits\n",
    "        if split == \"train\":\n",
    "            if m == target_type and label == 0:\n",
    "                target_train.append(entry)\n",
    "            elif m != target_type and label == 0:\n",
    "                po_train.append(entry)\n",
    "\n",
    "        # Test splits for final evaluation\n",
    "        elif split == \"test\":\n",
    "            if m == target_type:\n",
    "                if label == 0:\n",
    "                    target_test_normal.append(entry)\n",
    "                elif label == 1:\n",
    "                    target_test_anomaly.append(entry)\n",
    "\n",
    "    return {\n",
    "        \"target_train\": target_train,\n",
    "        \"po_train\": po_train,\n",
    "        \"target_test_normal\": target_test_normal,\n",
    "        \"target_test_anomaly\": target_test_anomaly,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03646fe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_train 3675\n",
      "po_train 16444\n",
      "target_test_normal 400\n",
      "target_test_anomaly 1475\n"
     ]
    }
   ],
   "source": [
    "splits = build_target_vs_po_lists(file_list, target_type=\"fan\")\n",
    "for k, v in splits.items():\n",
    "    print(k, len(v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0cc935f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProxyOUDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Binaire classificatie:\n",
    "        label=1 → target machine (normal)\n",
    "        label=0 → proxy outlier sample\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, entries, label, transform=None):\n",
    "        \"\"\"\n",
    "        entries : list of dicts uit scan_files()\n",
    "        label   : class label (1 = target, 0 = proxy outlier)\n",
    "        \"\"\"\n",
    "        self.entries = entries\n",
    "        self.label = label\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.entries[idx]\n",
    "        path = item[\"path\"]\n",
    "\n",
    "        audio, sr = load_audio(path)\n",
    "        spec = audio_to_logmelspec(audio, sr)   # (n_mels, n_frames)\n",
    "\n",
    "        # optioneel: korte spectrogrammen pad-of-crop\n",
    "        spec = torch.tensor(spec, dtype=torch.float32)\n",
    "\n",
    "        # Return (C, H, W)\n",
    "        spec = spec.unsqueeze(0)   # [1, n_mels, n_frames]\n",
    "\n",
    "        y = torch.tensor(self.label, dtype=torch.long)\n",
    "        return spec, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76bb1bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_spectrogram_batch(batch):\n",
    "    \"\"\"\n",
    "    Pad alle spectrogrammen in de batch rechts met nullen zodat\n",
    "    ze dezelfde tijd-dimensie (n_frames) hebben.\n",
    "\n",
    "    batch: list of (spec, label), waarbij\n",
    "           spec: [1, n_mels, T_i]\n",
    "           label: scalar tensor\n",
    "    return:\n",
    "           x: [B, 1, n_mels, T_max]\n",
    "           y: [B]\n",
    "    \"\"\"\n",
    "    specs, labels = zip(*batch)  # tuples van tensors\n",
    "\n",
    "    # Bepaal maximale lengte in deze batch\n",
    "    widths = [s.shape[-1] for s in specs]\n",
    "    max_w = max(widths)\n",
    "\n",
    "    batch_size = len(specs)\n",
    "    # Init met nullen\n",
    "    x = torch.zeros(batch_size, 1, N_MELS, max_w, dtype=specs[0].dtype)\n",
    "\n",
    "    for i, s in enumerate(specs):\n",
    "        T = s.shape[-1]\n",
    "        x[i, :, :, :T] = s  # vul tot eigen lengte\n",
    "\n",
    "    y = torch.stack(labels, dim=0)\n",
    "\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fba81dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 128, 344]) torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Klein testje met een handgemaakte \"batch\"\n",
    "a = torch.randn(1, N_MELS, 313)\n",
    "b = torch.randn(1, N_MELS, 344)\n",
    "\n",
    "xb, yb = collate_spectrogram_batch([(a, torch.tensor(1)), (b, torch.tensor(0))])\n",
    "print(xb.shape, yb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce705e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3675 16444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 128, 313]), tensor(1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_train_ds = ProxyOUDataset(splits[\"target_train\"], label=1)\n",
    "po_train_ds     = ProxyOUDataset(splits[\"po_train\"], label=0)\n",
    "\n",
    "print(len(target_train_ds), len(po_train_ds))\n",
    "\n",
    "spec, label = target_train_ds[0]\n",
    "spec.shape, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b178ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallConvClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    Simpele CNN die log-Mel spectrogrammen classificeert.\n",
    "    Output: 2 logits (target vs PO)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2, 2)),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((8, 8))\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 8 * 8, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "810aa2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0706, -0.0140],\n",
       "        [-0.0744, -0.0036]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SmallConvClassifier().to(device)\n",
    "\n",
    "dummy = torch.randn(2, 1, 128, 200).to(device)\n",
    "out = model(dummy)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a686b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_proxy_epoch(model, loader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "\n",
    "    for x, y in loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * x.size(0)\n",
    "\n",
    "        preds = logits.argmax(1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        count += x.size(0)\n",
    "\n",
    "    return total_loss / count, correct / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41e88e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_proxy_epoch(model, loader, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    count = 0\n",
    "    scores = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            loss = F.cross_entropy(logits, y)\n",
    "\n",
    "            total_loss += loss.item() * x.size(0)\n",
    "            preds = logits.argmax(1)\n",
    "            correct += (preds == y).sum().item()\n",
    "            count += x.size(0)\n",
    "\n",
    "            # Probability of class 1 (target)\n",
    "            probs = F.softmax(logits, dim=1)[:, 1]\n",
    "            scores.extend(probs.cpu().numpy())\n",
    "            labels.extend(y.cpu().numpy())\n",
    "\n",
    "    return (\n",
    "        total_loss / count,\n",
    "        correct / count,\n",
    "        np.array(scores),\n",
    "        np.array(labels),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d201fff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine target + PO into one training dataset\n",
    "train_ds = torch.utils.data.ConcatDataset([\n",
    "    ProxyOUDataset(splits[\"target_train\"], label=1),\n",
    "    ProxyOUDataset(splits[\"po_train\"], label=0)\n",
    "])\n",
    "\n",
    "test_ds = torch.utils.data.ConcatDataset([\n",
    "    ProxyOUDataset(splits[\"target_test_normal\"], label=1),\n",
    "    ProxyOUDataset(splits[\"target_test_anomaly\"], label=0),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43abeb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "num_target = len(splits[\"target_train\"])\n",
    "num_proxy = len(splits[\"po_train\"])\n",
    "\n",
    "weights = [1/num_target]*num_target + [1/num_proxy]*num_proxy\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, num_samples=num_target+num_proxy, replacement=True)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=16,\n",
    "    sampler=sampler,\n",
    "    collate_fn=collate_spectrogram_batch,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=8,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_spectrogram_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SmallConvClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "loss, acc = train_proxy_epoch(model, train_loader, optimizer, device)\n",
    "print(\"Train loss:\", loss, \"Acc:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a7c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4292188715338707\n",
      "Test Accuracy: 0.37546666666666667\n",
      "AUC: 0.6665152542372882\n"
     ]
    }
   ],
   "source": [
    "test_ds = torch.utils.data.ConcatDataset([\n",
    "    ProxyOUDataset(splits[\"target_test_normal\"], label=1),\n",
    "    ProxyOUDataset(splits[\"target_test_anomaly\"], label=0)\n",
    "])\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=8, shuffle=False)\n",
    "\n",
    "test_loss, test_acc, scores, labels = eval_proxy_epoch(model, test_loader, device)\n",
    "\n",
    "auc = metrics.roc_auc_score(labels, scores)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "print(\"AUC:\", auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bab0ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train target samples: 3675\n",
      "Train proxy samples : 16444\n",
      "Test normal samples : 400\n",
      "Test anomaly samples: 1475\n"
     ]
    }
   ],
   "source": [
    "print(\"Train target samples:\", len(splits[\"target_train\"]))\n",
    "print(\"Train proxy samples :\", len(splits[\"po_train\"]))\n",
    "print(\"Test normal samples :\", len(splits[\"target_test_normal\"]))\n",
    "print(\"Test anomaly samples:\", len(splits[\"target_test_anomaly\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256cfd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
