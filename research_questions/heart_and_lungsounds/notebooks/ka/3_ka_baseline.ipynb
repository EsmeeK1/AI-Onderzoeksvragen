{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'cuda'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "DEVICE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PROJECT_ROOT: C:\\Users\\MSI\\Documents\\Persoonlijke Projecten\\AI-Onderzoeksvragen\\research_questions\\heart_and_lungsounds\n",
            "CSV_PATH     : C:\\Users\\MSI\\Documents\\Persoonlijke Projecten\\AI-Onderzoeksvragen\\research_questions\\heart_and_lungsounds\\data\\processed\\ka\\ka_segments.csv\n",
            "OUT_DIR      : C:\\Users\\MSI\\Documents\\Persoonlijke Projecten\\AI-Onderzoeksvragen\\research_questions\\heart_and_lungsounds\\data\\processed\\ka\\baseline_runs_ka_all_labels\n",
            "CACHE_DIR    : C:\\Users\\MSI\\Documents\\Persoonlijke Projecten\\AI-Onderzoeksvragen\\research_questions\\heart_and_lungsounds\\data\\processed\\ka\\feature_cache\n"
          ]
        }
      ],
      "source": [
        "CWD = Path().resolve()\n",
        "PROJECT_ROOT = CWD.parents[1]\n",
        "\n",
        "OUT_ROOT = PROJECT_ROOT / \"data\" / \"processed\" / \"ka\"\n",
        "CSV_PATH = OUT_ROOT / \"ka_segments.csv\"\n",
        "\n",
        "OUT_DIR = OUT_ROOT / \"baseline_runs_ka_all_labels\"\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CACHE_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"ka\" / \"feature_cache\"\n",
        "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
        "print(\"CSV_PATH     :\", CSV_PATH)\n",
        "print(\"OUT_DIR      :\", OUT_DIR)\n",
        "print(\"CACHE_DIR    :\", CACHE_DIR)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Rows: 5174 | Missing audio: 0\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(CSV_PATH)\n",
        "\n",
        "if \"audio_path\" not in df.columns:\n",
        "    raise ValueError(\"Expected column 'audio_path' in ka_segments.csv\")\n",
        "\n",
        "def resolve_audio_path(p: str) -> Path:\n",
        "    p = str(p).strip()\n",
        "    return (PROJECT_ROOT / p).resolve()\n",
        "\n",
        "df[\"audio_path_resolved\"] = df[\"audio_path\"].astype(str).map(resolve_audio_path)\n",
        "df[\"audio_exists\"] = df[\"audio_path_resolved\"].map(lambda p: Path(p).exists())\n",
        "\n",
        "missing = (~df[\"audio_exists\"]).sum()\n",
        "print(\"Rows:\", len(df), \"| Missing audio:\", int(missing))\n",
        "\n",
        "df = df[df[\"audio_exists\"]].reset_index(drop=True)\n",
        "assert len(df) > 0, \"No audio found after resolving paths.\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "add32d18",
      "metadata": {},
      "outputs": [],
      "source": [
        "col = \"diagnosis_norm\"\n",
        "\n",
        "# drop echte NaN / missing\n",
        "df = df.dropna(subset=[col]).copy()\n",
        "\n",
        "# drop string-varianten van \"nan\" en lege strings\n",
        "s = df[col].astype(str).str.strip()\n",
        "df = df[~s.str.lower().isin([\"nan\", \"none\", \"\"])]  # voeg evt. \"unknown\" toe als je die ook wilt droppen\n",
        "df = df.reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a2068aa1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "diagnosis_norm\n",
              "Normal           1655\n",
              "Asthma           1446\n",
              "Heart Failure     942\n",
              "COPD              420\n",
              "Pneumonia         261\n",
              "BRON              102\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['diagnosis_norm'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "e87ad03d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num classes: 6\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "diagnosis_norm\n",
              "Normal           1655\n",
              "Asthma           1446\n",
              "Heart Failure     942\n",
              "COPD              420\n",
              "Pneumonia         261\n",
              "BRON              102\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LABEL_COL = \"diagnosis_norm\"\n",
        "GROUP_COL = \"patient_id\"\n",
        "\n",
        "if LABEL_COL not in df.columns:\n",
        "    raise ValueError(f\"Expected column '{LABEL_COL}' in ka_segments.csv\")\n",
        "if GROUP_COL not in df.columns:\n",
        "    raise ValueError(f\"Expected column '{GROUP_COL}' in ka_segments.csv\")\n",
        "\n",
        "df[LABEL_COL] = df[LABEL_COL].astype(str).str.strip()\n",
        "\n",
        "LABELS = sorted(df[LABEL_COL].unique().tolist())\n",
        "label2id = {l:i for i,l in enumerate(LABELS)}\n",
        "id2label = {i:l for l,i in label2id.items()}\n",
        "\n",
        "df[\"y\"] = df[LABEL_COL].map(label2id).astype(int)\n",
        "\n",
        "print(\"Num classes:\", len(LABELS))\n",
        "df[LABEL_COL].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "import numpy as np\n",
        "\n",
        "def _has_all_labels(df_split, label_col, labels):\n",
        "    present = set(df_split[label_col].unique().tolist())\n",
        "    return all(l in present for l in labels)\n",
        "\n",
        "def split_by_group_with_label_coverage(\n",
        "    df,\n",
        "    group_col,\n",
        "    label_col,\n",
        "    labels,\n",
        "    seed=42,\n",
        "    test_size=0.15,\n",
        "    val_size=0.15,\n",
        "    max_tries=2000,\n",
        "    min_per_split=1,   # zet bv 1 of 2\n",
        "):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    labels = list(labels)\n",
        "\n",
        "    def meets_min(df_split):\n",
        "        vc = df_split[label_col].value_counts()\n",
        "        return all(vc.get(l, 0) >= min_per_split for l in labels)\n",
        "\n",
        "    for _ in range(max_tries):\n",
        "        s1 = int(rng.randint(0, 10_000_000))\n",
        "        gss1 = GroupShuffleSplit(n_splits=1, test_size=test_size, random_state=s1)\n",
        "        tr_idx, te_idx = next(gss1.split(df, groups=df[group_col]))\n",
        "        df_tr = df.iloc[tr_idx].reset_index(drop=True)\n",
        "        df_te = df.iloc[te_idx].reset_index(drop=True)\n",
        "\n",
        "        if not _has_all_labels(df_te, label_col, labels):\n",
        "            continue\n",
        "        if min_per_split and not meets_min(df_te):\n",
        "            continue\n",
        "\n",
        "        # val uit train trekken\n",
        "        s2 = int(rng.randint(0, 10_000_000))\n",
        "        # val_size is fractie van totale df; binnen df_tr moet je hernormaliseren:\n",
        "        val_frac_within_tr = val_size / (1.0 - test_size)\n",
        "\n",
        "        gss2 = GroupShuffleSplit(n_splits=1, test_size=val_frac_within_tr, random_state=s2)\n",
        "        tr2_idx, va_idx = next(gss2.split(df_tr, groups=df_tr[group_col]))\n",
        "        df_train = df_tr.iloc[tr2_idx].reset_index(drop=True)\n",
        "        df_val   = df_tr.iloc[va_idx].reset_index(drop=True)\n",
        "\n",
        "        ok = (\n",
        "            _has_all_labels(df_train, label_col, labels) and\n",
        "            _has_all_labels(df_val,   label_col, labels) and\n",
        "            _has_all_labels(df_te,    label_col, labels)\n",
        "        )\n",
        "        if not ok:\n",
        "            continue\n",
        "\n",
        "        if min_per_split:\n",
        "            if not (meets_min(df_train) and meets_min(df_val) and meets_min(df_te)):\n",
        "                continue\n",
        "\n",
        "        return df_train, df_val, df_te\n",
        "\n",
        "    raise RuntimeError(\n",
        "        f\"Could not find a group split with full label coverage after {max_tries} tries. \"\n",
        "        f\"Likely too few groups for some labels.\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "dae4faf1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train, df_val, df_test = split_by_group_with_label_coverage(\n",
        "    df,\n",
        "    group_col=GROUP_COL,\n",
        "    label_col=\"diagnosis_norm\",\n",
        "    labels=LABELS,\n",
        "    seed=SEED,\n",
        "    test_size=0.15,\n",
        "    val_size=0.15,\n",
        "    max_tries=5000,\n",
        "    min_per_split=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "153a1e51",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Leakage: True True True\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "diagnosis_norm\n",
              "BRON              3\n",
              "Pneumonia         5\n",
              "COPD              9\n",
              "Heart Failure    21\n",
              "Asthma           32\n",
              "Normal           35\n",
              "Name: patient_id, dtype: int64"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Leakage:\",\n",
        "      len(set(df_train[GROUP_COL]) & set(df_val[GROUP_COL])) == 0,\n",
        "      len(set(df_train[GROUP_COL]) & set(df_test[GROUP_COL])) == 0,\n",
        "      len(set(df_val[GROUP_COL]) & set(df_test[GROUP_COL])) == 0)\n",
        "\n",
        "df.groupby(\"diagnosis_norm\")[GROUP_COL].nunique().sort_values()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_audio_mono_4k(path: Path, target_sr=4000):\n",
        "    y, sr = sf.read(str(path))\n",
        "    if y.ndim > 1:\n",
        "        y = np.mean(y, axis=1)\n",
        "    if sr != target_sr:\n",
        "        y = librosa.resample(y.astype(np.float32), orig_sr=sr, target_sr=target_sr)\n",
        "        sr = target_sr\n",
        "    return y.astype(np.float32), sr\n",
        "\n",
        "def fe_logmel(y, sr, n_mels=52, n_fft=256, hop_length=32, fmin=20, fmax=2000):\n",
        "    S = librosa.feature.melspectrogram(\n",
        "        y=y, sr=sr, n_fft=n_fft, hop_length=hop_length,\n",
        "        n_mels=n_mels, fmin=fmin, fmax=fmax, power=2.0\n",
        "    )\n",
        "    return librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
        "\n",
        "def fe_stft(y, sr, n_fft=256, hop_length=32):\n",
        "    Z = librosa.stft(y=y, n_fft=n_fft, hop_length=hop_length, center=True)\n",
        "    S = np.abs(Z) ** 2\n",
        "    return librosa.power_to_db(S, ref=np.max).astype(np.float32)\n",
        "\n",
        "def standardize(feat: np.ndarray):\n",
        "    m = float(np.mean(feat))\n",
        "    s = float(np.std(feat))\n",
        "    return (feat - m) / (s + 1e-6)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CachedFeatureDataset(Dataset):\n",
        "    def __init__(self, df: pd.DataFrame, feature_type: str, cache_dir: Path):\n",
        "        self.df = df.reset_index(drop=True)\n",
        "        self.feature_type = str(feature_type).lower().strip()\n",
        "        self.cache_dir = Path(cache_dir)\n",
        "        self.cache_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def _cache_path(self, idx: int) -> Path:\n",
        "        row = self.df.iloc[idx]\n",
        "        stem = Path(row[\"audio_path_resolved\"]).stem\n",
        "        return self.cache_dir / self.feature_type / f\"{stem}.npy\"\n",
        "\n",
        "    def __getitem__(self, idx: int):\n",
        "        row = self.df.iloc[idx]\n",
        "        y = int(row[\"y\"])\n",
        "\n",
        "        cpath = self._cache_path(idx)\n",
        "        cpath.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        if cpath.exists():\n",
        "            feat = np.load(cpath)\n",
        "        else:\n",
        "            y_audio, sr = load_audio_mono_4k(Path(row[\"audio_path_resolved\"]))\n",
        "            if self.feature_type == \"logmel\":\n",
        "                feat = fe_logmel(y_audio, sr)\n",
        "            elif self.feature_type == \"stft\":\n",
        "                feat = fe_stft(y_audio, sr)\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown feature_type: {self.feature_type}\")\n",
        "            feat = standardize(feat)\n",
        "            np.save(cpath, feat)\n",
        "\n",
        "        x = torch.from_numpy(feat).unsqueeze(0)  # (1, F, T)\n",
        "        return x.float(), torch.tensor(y, dtype=torch.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "class SmallCNN(nn.Module):\n",
        "    def __init__(self, n_classes: int):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, kernel_size=(4, 2), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "\n",
        "            nn.Conv2d(8, 32, kernel_size=(4, 2), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "\n",
        "            nn.Conv2d(32, 32, kernel_size=(4, 2), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2)),\n",
        "\n",
        "            nn.Conv2d(32, 32, kernel_size=(4, 2), padding=(1, 0)),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2), stride=(1, 2)),\n",
        "        )\n",
        "        self.dropout1 = nn.Dropout(0.25)\n",
        "        self.fc1 = nn.Linear(1, 512)  # lazy init\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, n_classes)\n",
        "        self._lazy = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.features(x)\n",
        "        z = torch.flatten(z, 1)\n",
        "        z = self.dropout1(z)\n",
        "        if self._lazy:\n",
        "            self.fc1 = nn.Linear(z.shape[1], 512).to(z.device)\n",
        "            self._lazy = False\n",
        "        z = self.fc1(z)\n",
        "        z = self.relu(z)\n",
        "        z = self.dropout2(z)\n",
        "        return self.fc2(z)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model, dl):\n",
        "    model.eval()\n",
        "    total_loss, total_n, total_correct = 0.0, 0, 0\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    for xb, yb in dl:\n",
        "        xb = xb.to(DEVICE)\n",
        "        yb = yb.to(DEVICE)\n",
        "\n",
        "        logits = model(xb)\n",
        "        loss = criterion(logits, yb)\n",
        "\n",
        "        total_loss += float(loss.item()) * len(yb)\n",
        "        total_n += len(yb)\n",
        "\n",
        "        pred = torch.argmax(logits, dim=1)\n",
        "        total_correct += int((pred == yb).sum().item())\n",
        "\n",
        "        y_true.extend(yb.cpu().numpy().tolist())\n",
        "        y_pred.extend(pred.cpu().numpy().tolist())\n",
        "\n",
        "    return total_loss / max(total_n, 1), total_correct / max(total_n, 1), y_true, y_pred\n",
        "\n",
        "def class_weights_from_df(df_train: pd.DataFrame, n_classes: int) -> torch.Tensor:\n",
        "    counts = df_train[\"y\"].value_counts().reindex(range(n_classes), fill_value=0).astype(float)\n",
        "    inv = 1.0 / np.maximum(counts.values, 1.0)\n",
        "    w = inv / np.mean(inv)\n",
        "    return torch.tensor(w, dtype=torch.float32)\n",
        "\n",
        "def make_sampler(df_train: pd.DataFrame, n_classes: int) -> WeightedRandomSampler:\n",
        "    counts = df_train[\"y\"].value_counts().reindex(range(n_classes), fill_value=0).astype(float)\n",
        "    inv = 1.0 / np.maximum(counts.values, 1.0)\n",
        "    w = inv[df_train[\"y\"].values]\n",
        "    return WeightedRandomSampler(weights=torch.tensor(w, dtype=torch.double), num_samples=len(w), replacement=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_experiment(feature_type=\"logmel\", use_weights=True, use_sampler=False, epochs=50, batch_size=8, lr=1e-3):\n",
        "    run_dir = OUT_DIR / f\"{feature_type}__weights_{int(use_weights)}__sampler_{int(use_sampler)}\"\n",
        "    run_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    ds_tr = CachedFeatureDataset(df_train, feature_type, cache_dir=CACHE_DIR)\n",
        "    ds_va = CachedFeatureDataset(df_val, feature_type, cache_dir=CACHE_DIR)\n",
        "    ds_te = CachedFeatureDataset(df_test, feature_type, cache_dir=CACHE_DIR)\n",
        "\n",
        "    if use_sampler:\n",
        "        sampler = make_sampler(df_train, n_classes=len(LABELS))\n",
        "        dl_tr = DataLoader(ds_tr, batch_size=batch_size, sampler=sampler, shuffle=False, num_workers=0)\n",
        "    else:\n",
        "        dl_tr = DataLoader(ds_tr, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "\n",
        "    dl_va = DataLoader(ds_va, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "    dl_te = DataLoader(ds_te, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "    model = SmallCNN(n_classes=len(LABELS)).to(DEVICE)\n",
        "\n",
        "    if use_weights:\n",
        "        w = class_weights_from_df(df_train, len(LABELS)).to(DEVICE)\n",
        "        criterion = nn.CrossEntropyLoss(weight=w)\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    history = []\n",
        "    best_val_loss = float(\"inf\")\n",
        "    best_path = run_dir / \"best.pt\"\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        model.train()\n",
        "        tr_loss, tr_n, tr_correct = 0.0, 0, 0\n",
        "\n",
        "        for xb, yb in dl_tr:\n",
        "            xb = xb.to(DEVICE)\n",
        "            yb = yb.to(DEVICE)\n",
        "\n",
        "            optim.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = criterion(logits, yb)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "\n",
        "            tr_loss += float(loss.item()) * len(yb)\n",
        "            tr_n += len(yb)\n",
        "            tr_correct += int((torch.argmax(logits, dim=1) == yb).sum().item())\n",
        "\n",
        "        train_loss = tr_loss / max(tr_n, 1)\n",
        "        train_acc = tr_correct / max(tr_n, 1)\n",
        "\n",
        "        val_loss, val_acc, _, _ = evaluate(model, dl_va)\n",
        "\n",
        "        history.append({\n",
        "            \"epoch\": ep,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"train_acc\": train_acc,\n",
        "            \"val_acc\": val_acc\n",
        "        })\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), best_path)\n",
        "\n",
        "    pd.DataFrame(history).to_csv(run_dir / \"history.csv\", index=False)\n",
        "\n",
        "    model.load_state_dict(torch.load(best_path, map_location=DEVICE))\n",
        "\n",
        "    test_loss, test_acc, y_true, y_pred = evaluate(model, dl_te)\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(LABELS))))\n",
        "    np.save(run_dir / \"confusion_matrix.npy\", cm)\n",
        "\n",
        "    rep = classification_report(\n",
        "        y_true, y_pred,\n",
        "        labels=list(range(len(LABELS))),\n",
        "        target_names=LABELS,\n",
        "        output_dict=True,\n",
        "        zero_division=0\n",
        "    )\n",
        "    pd.DataFrame(rep).T.to_csv(run_dir / \"test_classification_report.csv\")\n",
        "\n",
        "    with open(run_dir / \"test_summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(f\"feature_type: {feature_type}\\n\")\n",
        "        f.write(f\"use_weights: {use_weights}\\n\")\n",
        "        f.write(f\"use_sampler: {use_sampler}\\n\")\n",
        "        f.write(f\"test_loss: {test_loss:.6f}\\n\")\n",
        "        f.write(f\"test_acc: {test_acc:.6f}\\n\")\n",
        "\n",
        "    return {\n",
        "        \"run\": run_dir.name,\n",
        "        \"feature\": feature_type,\n",
        "        \"weights\": int(use_weights),\n",
        "        \"sampler\": int(use_sampler),\n",
        "        \"test_loss\": float(test_loss),\n",
        "        \"test_acc\": float(test_acc),\n",
        "        \"macro_f1\": float(rep[\"macro avg\"][\"f1-score\"]),\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "runs = []\n",
        "for feat in [\"logmel\", \"stft\"]:\n",
        "    for w in [0, 1]:\n",
        "        for s in [0, 1]:\n",
        "            runs.append(run_experiment(feature_type=feat, use_weights=bool(w), use_sampler=bool(s), epochs=50))\n",
        "\n",
        "summary_df = pd.DataFrame(runs).sort_values(\"macro_f1\", ascending=False).reset_index(drop=True)\n",
        "summary_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def exp_title(exp_dir: Path) -> str:\n",
        "    name = exp_dir.name\n",
        "    feat = name.split(\"__\")[0].upper()\n",
        "    w = \"Yes\" if \"weights_1\" in name else \"No\"\n",
        "    s = \"Yes\" if \"sampler_1\" in name else \"No\"\n",
        "    return f\"KA Baseline | Target: {LABEL_COL} | Features: {feat} | Class Weights: {w} | Sampler: {s}\"\n",
        "\n",
        "def plot_curves(exp_dir: Path, dpi=300):\n",
        "    exp_dir = Path(exp_dir)\n",
        "    hist = pd.read_csv(exp_dir / \"history.csv\")\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7.2, 3.1), dpi=dpi, constrained_layout=True)\n",
        "    fig.suptitle(exp_title(exp_dir), fontsize=10.5, fontweight=\"bold\")\n",
        "\n",
        "    ax1.plot(hist[\"epoch\"], hist[\"train_acc\"], label=\"Train\", linewidth=2)\n",
        "    ax1.plot(hist[\"epoch\"], hist[\"val_acc\"], label=\"Validation\", linewidth=2)\n",
        "    ax1.set_xlabel(\"Epoch\"); ax1.set_ylabel(\"Accuracy\"); ax1.set_ylim(0, 1.0)\n",
        "    ax1.grid(True, alpha=0.3); ax1.legend(frameon=False, fontsize=9)\n",
        "\n",
        "    ax2.plot(hist[\"epoch\"], hist[\"train_loss\"], label=\"Train\", linewidth=2)\n",
        "    ax2.plot(hist[\"epoch\"], hist[\"val_loss\"], label=\"Validation\", linewidth=2)\n",
        "    ax2.set_xlabel(\"Epoch\"); ax2.set_ylabel(\"Loss\")\n",
        "    ax2.grid(True, alpha=0.3); ax2.legend(frameon=False, fontsize=9)\n",
        "\n",
        "    fig.savefig(exp_dir / \"plot_curves_acc_loss.png\", bbox_inches=\"tight\")\n",
        "    return fig\n",
        "\n",
        "def plot_cm(exp_dir: Path, normalize=\"true\", dpi=300):\n",
        "    exp_dir = Path(exp_dir)\n",
        "    cm = np.load(exp_dir / \"confusion_matrix.npy\").astype(float)\n",
        "\n",
        "    if normalize == \"true\":\n",
        "        denom = cm.sum(axis=1, keepdims=True)\n",
        "        cm = np.divide(cm, denom, out=np.zeros_like(cm), where=denom != 0)\n",
        "        fmt = \".2f\"\n",
        "        sub = \"Confusion Matrix (Normalized)\"\n",
        "    else:\n",
        "        fmt = \".0f\"\n",
        "        sub = \"Confusion Matrix (Counts)\"\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6.2, 5.1), dpi=dpi, constrained_layout=True)\n",
        "    ax.set_title(f\"{exp_title(exp_dir)}\\n{sub}\", fontsize=9.5, fontweight=\"bold\")\n",
        "\n",
        "    im = ax.imshow(cm)\n",
        "    fig.colorbar(im, ax=ax, fraction=0.05)\n",
        "\n",
        "    ax.set_xticks(range(len(LABELS))); ax.set_yticks(range(len(LABELS)))\n",
        "    ax.set_xticklabels(LABELS, rotation=30, ha=\"right\", fontsize=8)\n",
        "    ax.set_yticklabels(LABELS, fontsize=8)\n",
        "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\")\n",
        "\n",
        "    for i in range(len(LABELS)):\n",
        "        for j in range(len(LABELS)):\n",
        "            ax.text(j, i, format(cm[i, j], fmt), ha=\"center\", va=\"center\", fontsize=6.5)\n",
        "\n",
        "    fig.savefig(exp_dir / f\"plot_confusion_matrix_{normalize}.png\", bbox_inches=\"tight\")\n",
        "    return fig\n",
        "\n",
        "def plot_report(exp_dir: Path, dpi=300):\n",
        "    exp_dir = Path(exp_dir)\n",
        "    rep = pd.read_csv(exp_dir / \"test_classification_report.csv\", index_col=0)\n",
        "    if \"f1-score\" not in rep.columns:\n",
        "        rep = rep.T\n",
        "    rep = rep[[\"precision\", \"recall\", \"f1-score\", \"support\"]].round(3)\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(7.0, 3.2), dpi=dpi, constrained_layout=True)\n",
        "    ax.set_title(f\"{exp_title(exp_dir)}\\nClassification Report (Test)\", fontsize=9.5, fontweight=\"bold\")\n",
        "    ax.axis(\"off\")\n",
        "\n",
        "    table = ax.table(\n",
        "        cellText=rep.values,\n",
        "        rowLabels=rep.index.tolist(),\n",
        "        colLabels=[c.upper() for c in rep.columns],\n",
        "        loc=\"center\",\n",
        "        cellLoc=\"center\"\n",
        "    )\n",
        "    table.auto_set_font_size(False)\n",
        "    table.set_fontsize(7.8)\n",
        "    table.scale(1, 1.12)\n",
        "\n",
        "    fig.savefig(exp_dir / \"plot_classification_report.png\", bbox_inches=\"tight\")\n",
        "    return fig\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for run_name in summary_df[\"run\"].tolist():\n",
        "    d = OUT_DIR / run_name\n",
        "    plot_curves(d)\n",
        "    plot_cm(d, normalize=\"true\")\n",
        "    plot_report(d)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bb913059",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
